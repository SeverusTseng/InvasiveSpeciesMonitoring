{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#Load-libraries\" data-toc-modified-id=\"Load-libraries-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Load libraries</a></div><div class=\"lev1 toc-item\"><a href=\"#Load-pre-trained-vgg-model-and-add-top-layers\" data-toc-modified-id=\"Load-pre-trained-vgg-model-and-add-top-layers-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load pre-trained vgg model and add top layers</a></div><div class=\"lev1 toc-item\"><a href=\"#Image-data-generators\" data-toc-modified-id=\"Image-data-generators-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Image data generators</a></div><div class=\"lev1 toc-item\"><a href=\"#Training---300x225\" data-toc-modified-id=\"Training---300x225-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Training - 300x225</a></div><div class=\"lev1 toc-item\"><a href=\"#Training---600x450\" data-toc-modified-id=\"Training---600x450-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Training - 600x450</a></div><div class=\"lev1 toc-item\"><a href=\"#Training-convolutional-layers\" data-toc-modified-id=\"Training-convolutional-layers-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Training convolutional layers</a></div><div class=\"lev1 toc-item\"><a href=\"#Prediction\" data-toc-modified-id=\"Prediction-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Prediction</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "modified from https://www.kaggle.com/chmaxx/finetune-vgg16-0-97-with-minimal-effort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "pd.options.display.max_rows = 40"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained vgg model and add top layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 34s 1us/step\n",
      "58900480/58889256 [==============================] - 34s 1us/step\n"
     ]
    }
   ],
   "source": [
    "vgg16 = VGG16(weights = 'imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vgg16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vgg16.get_layer('block5_conv3').output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model_final = Model(inputs=vgg16.input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model_final.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, None, None, 64)    1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, None, None, 64)    36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, None, None, 128)   73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, None, None, 128)   147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, None, None, 256)   295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, None, None, 256)   590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, None, None, 512)   1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, None, None, 512)   2359808   \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,846,273\n",
      "Trainable params: 131,585\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_final.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image data generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator( \n",
    "    featurewise_center            = True,\n",
    "    rescale                       = 1.,\n",
    "    rotation_range                = 10,\n",
    "    width_shift_range             = .1,\n",
    "    height_shift_range            = .1,\n",
    "    shear_range                   = 0.2,\n",
    "    zoom_range                    = 0.2,\n",
    "    horizontal_flip               = True,\n",
    "    vertical_flip                 = False,\n",
    "    fill_mode                     = \"reflect\")\n",
    "\n",
    "# normalization neccessary for correct image input to VGG16\n",
    "datagen.mean=np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape(1,1,3)\n",
    "\n",
    "# no data augmentation for validation and test set\n",
    "validgen = ImageDataGenerator(rescale=1., featurewise_center=True)\n",
    "validgen.mean=np.array([103.939, 116.779, 123.68], dtype=np.float32).reshape(1,1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1713 images belonging to 2 classes.\n",
      "Found 582 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# 600/450 _ 500/375 _ 400/300 _ 300/225\n",
    "\n",
    "img_width  = 300\n",
    "img_height = 225\n",
    "\n",
    "train_data_dir      = \"data/train\"\n",
    "validation_data_dir = \"data/valid\"\n",
    "test_data_dir       = \"data/test\"\n",
    "\n",
    "batch_size_train = 5\n",
    "batch_size_val   = 15\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        directory   = train_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_train,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = True)\n",
    "\n",
    "val_gen = validgen.flow_from_directory(\n",
    "        directory   = validation_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_val,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = False)\n",
    "\n",
    "test_gen = validgen.flow_from_directory(\n",
    "        directory   = test_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_val,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = False)\n",
    "\n",
    "train_samples      = len(train_gen.filenames)\n",
    "validation_samples = len(val_gen.filenames)\n",
    "test_samples       = len(test_gen.filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - 300x225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1634c23d3774d3fbd095bf162d11961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Training', max=10), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ef6891a7a6a46049cd680201922dbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Epoch 0', max=342), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 1634s - loss: 0.3109 - acc: 0.8840 - val_loss: 0.2244 - val_acc: 0.9088\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '342.0'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-982dea360d6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                           \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mverbose\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                           callbacks        = [early_stopping, TQDMNotebookCallback(), checkpoint])\n\u001b[0m",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2266\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2268\u001b[0;31m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2269\u001b[0m                 \u001b[0mepoch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2270\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcallback_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/callbacks.pyc\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras_tqdm/tqdm_callback.pyc\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminiters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmininterval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minner_total\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm_inner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_outer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tqdm/_tqdm_notebook.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0;31m# as the interrupt will most likely happen on another statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbar_style\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'danger'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: '342.0'"
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-iter-1-epoch-{epoch:02d}.hdf5\",\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(generator        = train_gen,\n",
    "                          epochs           = 10, \n",
    "                          steps_per_epoch  = math.ceil(train_samples / batch_size_train), \n",
    "                          validation_data  = val_gen, \n",
    "                          validation_steps = math.ceil(validation_samples / batch_size_val), \n",
    "                          verbose          = 2,\n",
    "                          callbacks        = [early_stopping, TQDMNotebookCallback(), checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training - 600x450"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1713 images belonging to 2 classes.\n",
      "Found 582 images belonging to 2 classes.\n",
      "Found 0 images belonging to 0 classes.\n"
     ]
    }
   ],
   "source": [
    "# 600/450 _ 500/375 _ 400/300 _ 300/225\n",
    "\n",
    "img_width  = 600\n",
    "img_height = 450\n",
    "\n",
    "train_data_dir      = \"data/train\"\n",
    "validation_data_dir = \"data/valid\"\n",
    "test_data_dir       = \"data/test\"\n",
    "\n",
    "batch_size_train = 5\n",
    "batch_size_val   = 15\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "        directory   = train_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_train,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = True)\n",
    "\n",
    "val_gen = validgen.flow_from_directory(\n",
    "        directory   = validation_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_val,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = False)\n",
    "\n",
    "test_gen = validgen.flow_from_directory(\n",
    "        directory   = test_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = batch_size_val,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = False)\n",
    "\n",
    "train_samples      = len(train_gen.filenames)\n",
    "validation_samples = len(val_gen.filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e30fc748e5a4b74a108fd181e4a3fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Training', max=10), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18cea7fff714b37aa58fa1c6356da79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description=u'Epoch 0', max=342), HTML(value=u'')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b256d47c69d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m                           \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_samples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbatch_size_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                           \u001b[0mverbose\u001b[0m          \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                           callbacks        = [early_stopping, TQDMNotebookCallback(), checkpoint])\n\u001b[0m",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   2248\u001b[0m                                 \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2249\u001b[0m                                 \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2250\u001b[0;31m                                 max_queue_size=max_queue_size)\n\u001b[0m\u001b[1;32m   2251\u001b[0m                         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2252\u001b[0m                             \u001b[0;31m# No need for try/except because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/legacy/interfaces.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mevaluate_generator\u001b[0;34m(self, generator, steps, max_queue_size, workers, use_multiprocessing, verbose)\u001b[0m\n\u001b[1;32m   2397\u001b[0m                                      \u001b[0;34m'or (x, y). Found: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2398\u001b[0m                                      str(generator_output))\n\u001b[0;32m-> 2399\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2400\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2401\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mtest_on_batch\u001b[0;34m(self, x, y, sample_weight)\u001b[0m\n\u001b[1;32m   1922\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_test_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1924\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1925\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1926\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2482\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2483\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/zengruolan/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-iter-2-epoch-{epoch:02d}.hdf5\",\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(generator        = train_gen,\n",
    "                          epochs           = 10, \n",
    "                          steps_per_epoch  = math.ceil(train_samples / batch_size_train), \n",
    "                          validation_data  = val_gen, \n",
    "                          validation_steps = math.ceil(validation_samples / batch_size_val), \n",
    "                          verbose          = 2,\n",
    "                          callbacks        = [early_stopping, TQDMNotebookCallback(), checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 block1_conv1\n",
      "2 block1_conv2\n",
      "3 block1_pool\n",
      "4 block2_conv1\n",
      "5 block2_conv2\n",
      "6 block2_pool\n",
      "7 block3_conv1\n",
      "8 block3_conv2\n",
      "9 block3_conv3\n",
      "10 block3_pool\n",
      "11 block4_conv1\n",
      "12 block4_conv2\n",
      "13 block4_conv3\n",
      "14 block4_pool\n",
      "15 block5_conv1\n",
      "16 block5_conv2\n",
      "17 block5_conv3\n",
      "18 global_average_pooling2d_1\n",
      "19 dense_1\n",
      "20 dropout_1\n",
      "21 dense_2\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model_final.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "for layer in model_final.layers[:15]:\n",
    "   layer.trainable = False\n",
    "for layer in model_final.layers[15:]:\n",
    "   layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_final.compile(optimizer = SGD(lr=0.0001, momentum=0.9, nesterov=True),\n",
    "                    loss      = 'binary_crossentropy',\n",
    "                    metrics   = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f324b7e8d3944e9bb89b605246b04333"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c60cc10ffdc408fae412e6735b9100b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "287s - loss: 0.1699 - acc: 0.9399 - val_loss: 0.1338 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f044a123f242ddb44871226b9f3734"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10\n",
      "287s - loss: 0.1123 - acc: 0.9642 - val_loss: 0.1374 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e52a1ce1db104629b39b7d0f57ac3acd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10\n",
      "287s - loss: 0.0688 - acc: 0.9769 - val_loss: 0.0914 - val_acc: 0.9718\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4299f3ca53364607a6889df9008cbff2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "287s - loss: 0.0571 - acc: 0.9803 - val_loss: 0.1304 - val_acc: 0.9577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b286f042b2b41d8ae0f26bb516b0f1b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10\n",
      "287s - loss: 0.0636 - acc: 0.9786 - val_loss: 0.1062 - val_acc: 0.9683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ea1ac54f46244a4a4b8888f9ecce1fc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10\n",
      "287s - loss: 0.0518 - acc: 0.9850 - val_loss: 0.0626 - val_acc: 0.9859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5200cf88b7a1415da0b3b4e34fab1b94"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "287s - loss: 0.0373 - acc: 0.9908 - val_loss: 0.1168 - val_acc: 0.9683\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02313d1ec3b4e3fbd1be9b26a6306c6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10\n",
      "287s - loss: 0.0298 - acc: 0.9890 - val_loss: 0.0920 - val_acc: 0.9824\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad5ed21478b4efaa309d604aca0fd1f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10\n",
      "287s - loss: 0.0259 - acc: 0.9913 - val_loss: 0.0991 - val_acc: 0.9806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2170b07cd94547d8a87aa92c1458c7ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10\n",
      "287s - loss: 0.0305 - acc: 0.9890 - val_loss: 0.0815 - val_acc: 0.9842\n",
      "Epoch 00009: early stopping\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3d7e7630f0>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = ModelCheckpoint(\"weights-iter-3-epoch-{epoch:02d}.hdf5\",\n",
    "                             monitor='val_acc',\n",
    "                             verbose=0,\n",
    "                             save_best_only=False,\n",
    "                             save_weights_only=True)\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=1, mode='auto')\n",
    "\n",
    "model_final.fit_generator(generator        = train_gen,\n",
    "                          epochs           = 10, \n",
    "                          steps_per_epoch  = math.ceil(train_samples / batch_size_train), \n",
    "                          validation_data  = val_gen, \n",
    "                          validation_steps = math.ceil(validation_samples / batch_size_val), \n",
    "                          verbose          = 2,\n",
    "                          callbacks        = [early_stopping, TQDMNotebookCallback(), checkpoint])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1531 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_gen = validgen.flow_from_directory(\n",
    "        directory   = test_data_dir,\n",
    "        target_size = (img_height, img_width),\n",
    "        batch_size  = 32,\n",
    "        class_mode  = \"binary\",\n",
    "        shuffle     = False)\n",
    "test_samples = len(test_gen.filenames)\n",
    "preds = model_final.predict_generator(test_gen, math.ceil(test_samples / 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.28751271e-03],\n",
       "       [  1.06840848e-03],\n",
       "       [  1.57627165e-01],\n",
       "       ..., \n",
       "       [  5.91619834e-02],\n",
       "       [  2.59617136e-05],\n",
       "       [  1.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_filenames = test_gen.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preds_filenames = [int(x.replace(\"unknown/\", \"\").replace(\".jpg\", \"\")) for x in preds_filenames]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1098,\n",
       " 718,\n",
       " 326,\n",
       " 1079,\n",
       " 688,\n",
       " 527,\n",
       " 86,\n",
       " 506,\n",
       " 1047,\n",
       " 211,\n",
       " 1422,\n",
       " 1306,\n",
       " 1115,\n",
       " 874,\n",
       " 742,\n",
       " 23,\n",
       " 501,\n",
       " 678,\n",
       " 1399,\n",
       " 1461,\n",
       " 1039,\n",
       " 936,\n",
       " 994,\n",
       " 1077,\n",
       " 1358,\n",
       " 487,\n",
       " 341,\n",
       " 704,\n",
       " 746,\n",
       " 20,\n",
       " 1049,\n",
       " 545,\n",
       " 762,\n",
       " 651,\n",
       " 1424,\n",
       " 1259,\n",
       " 1466,\n",
       " 220,\n",
       " 225,\n",
       " 332,\n",
       " 269,\n",
       " 919,\n",
       " 277,\n",
       " 251,\n",
       " 842,\n",
       " 992,\n",
       " 1264,\n",
       " 1099,\n",
       " 911,\n",
       " 1017,\n",
       " 978,\n",
       " 1391,\n",
       " 888,\n",
       " 405,\n",
       " 1129,\n",
       " 1505,\n",
       " 810,\n",
       " 1097,\n",
       " 1244,\n",
       " 363,\n",
       " 1202,\n",
       " 784,\n",
       " 12,\n",
       " 498,\n",
       " 275,\n",
       " 1366,\n",
       " 826,\n",
       " 879,\n",
       " 1016,\n",
       " 680,\n",
       " 448,\n",
       " 293,\n",
       " 1239,\n",
       " 1411,\n",
       " 1048,\n",
       " 34,\n",
       " 1498,\n",
       " 1400,\n",
       " 657,\n",
       " 347,\n",
       " 1263,\n",
       " 1413,\n",
       " 668,\n",
       " 352,\n",
       " 135,\n",
       " 645,\n",
       " 1025,\n",
       " 226,\n",
       " 63,\n",
       " 1112,\n",
       " 1203,\n",
       " 51,\n",
       " 457,\n",
       " 475,\n",
       " 866,\n",
       " 881,\n",
       " 1297,\n",
       " 904,\n",
       " 1294,\n",
       " 236,\n",
       " 1439,\n",
       " 856,\n",
       " 474,\n",
       " 1211,\n",
       " 613,\n",
       " 1242,\n",
       " 443,\n",
       " 599,\n",
       " 887,\n",
       " 411,\n",
       " 154,\n",
       " 1206,\n",
       " 1469,\n",
       " 555,\n",
       " 640,\n",
       " 681,\n",
       " 314,\n",
       " 1468,\n",
       " 1345,\n",
       " 245,\n",
       " 706,\n",
       " 392,\n",
       " 664,\n",
       " 632,\n",
       " 1437,\n",
       " 1166,\n",
       " 1458,\n",
       " 42,\n",
       " 739,\n",
       " 323,\n",
       " 608,\n",
       " 1061,\n",
       " 597,\n",
       " 32,\n",
       " 210,\n",
       " 955,\n",
       " 132,\n",
       " 109,\n",
       " 639,\n",
       " 551,\n",
       " 156,\n",
       " 284,\n",
       " 1530,\n",
       " 1287,\n",
       " 1321,\n",
       " 414,\n",
       " 99,\n",
       " 1230,\n",
       " 1300,\n",
       " 540,\n",
       " 1508,\n",
       " 113,\n",
       " 1065,\n",
       " 1364,\n",
       " 45,\n",
       " 1351,\n",
       " 283,\n",
       " 233,\n",
       " 562,\n",
       " 105,\n",
       " 754,\n",
       " 264,\n",
       " 1349,\n",
       " 1488,\n",
       " 1233,\n",
       " 184,\n",
       " 1272,\n",
       " 618,\n",
       " 734,\n",
       " 148,\n",
       " 1453,\n",
       " 1504,\n",
       " 1253,\n",
       " 513,\n",
       " 884,\n",
       " 1275,\n",
       " 1333,\n",
       " 1389,\n",
       " 1531,\n",
       " 1182,\n",
       " 1493,\n",
       " 1347,\n",
       " 655,\n",
       " 425,\n",
       " 1418,\n",
       " 35,\n",
       " 136,\n",
       " 133,\n",
       " 715,\n",
       " 1128,\n",
       " 643,\n",
       " 1257,\n",
       " 227,\n",
       " 1313,\n",
       " 813,\n",
       " 615,\n",
       " 33,\n",
       " 359,\n",
       " 792,\n",
       " 592,\n",
       " 1187,\n",
       " 765,\n",
       " 1162,\n",
       " 1337,\n",
       " 478,\n",
       " 1472,\n",
       " 1054,\n",
       " 925,\n",
       " 205,\n",
       " 188,\n",
       " 833,\n",
       " 398,\n",
       " 1045,\n",
       " 162,\n",
       " 1001,\n",
       " 267,\n",
       " 1243,\n",
       " 395,\n",
       " 604,\n",
       " 1215,\n",
       " 1464,\n",
       " 1307,\n",
       " 1293,\n",
       " 943,\n",
       " 49,\n",
       " 1119,\n",
       " 1131,\n",
       " 1136,\n",
       " 794,\n",
       " 200,\n",
       " 1189,\n",
       " 770,\n",
       " 1490,\n",
       " 1036,\n",
       " 1420,\n",
       " 1436,\n",
       " 1462,\n",
       " 484,\n",
       " 939,\n",
       " 790,\n",
       " 630,\n",
       " 1034,\n",
       " 66,\n",
       " 789,\n",
       " 381,\n",
       " 1216,\n",
       " 81,\n",
       " 461,\n",
       " 147,\n",
       " 620,\n",
       " 1497,\n",
       " 1452,\n",
       " 933,\n",
       " 870,\n",
       " 165,\n",
       " 962,\n",
       " 558,\n",
       " 875,\n",
       " 969,\n",
       " 839,\n",
       " 196,\n",
       " 454,\n",
       " 90,\n",
       " 180,\n",
       " 528,\n",
       " 1435,\n",
       " 1093,\n",
       " 117,\n",
       " 1271,\n",
       " 204,\n",
       " 29,\n",
       " 899,\n",
       " 574,\n",
       " 526,\n",
       " 1245,\n",
       " 237,\n",
       " 1096,\n",
       " 1387,\n",
       " 54,\n",
       " 1113,\n",
       " 313,\n",
       " 444,\n",
       " 889,\n",
       " 596,\n",
       " 159,\n",
       " 586,\n",
       " 1158,\n",
       " 1062,\n",
       " 262,\n",
       " 1069,\n",
       " 796,\n",
       " 1003,\n",
       " 256,\n",
       " 1414,\n",
       " 1308,\n",
       " 382,\n",
       " 1117,\n",
       " 1126,\n",
       " 821,\n",
       " 660,\n",
       " 659,\n",
       " 1416,\n",
       " 1284,\n",
       " 287,\n",
       " 890,\n",
       " 8,\n",
       " 1135,\n",
       " 690,\n",
       " 336,\n",
       " 991,\n",
       " 365,\n",
       " 940,\n",
       " 212,\n",
       " 838,\n",
       " 1107,\n",
       " 740,\n",
       " 1074,\n",
       " 368,\n",
       " 685,\n",
       " 408,\n",
       " 112,\n",
       " 709,\n",
       " 647,\n",
       " 213,\n",
       " 1019,\n",
       " 476,\n",
       " 897,\n",
       " 1127,\n",
       " 953,\n",
       " 1138,\n",
       " 465,\n",
       " 337,\n",
       " 421,\n",
       " 873,\n",
       " 1052,\n",
       " 100,\n",
       " 1382,\n",
       " 222,\n",
       " 128,\n",
       " 146,\n",
       " 602,\n",
       " 701,\n",
       " 1185,\n",
       " 977,\n",
       " 1177,\n",
       " 229,\n",
       " 428,\n",
       " 351,\n",
       " 767,\n",
       " 192,\n",
       " 149,\n",
       " 1526,\n",
       " 242,\n",
       " 371,\n",
       " 768,\n",
       " 22,\n",
       " 459,\n",
       " 577,\n",
       " 214,\n",
       " 13,\n",
       " 207,\n",
       " 410,\n",
       " 386,\n",
       " 829,\n",
       " 1363,\n",
       " 366,\n",
       " 1088,\n",
       " 1494,\n",
       " 1522,\n",
       " 572,\n",
       " 1248,\n",
       " 143,\n",
       " 52,\n",
       " 169,\n",
       " 956,\n",
       " 644,\n",
       " 1346,\n",
       " 1322,\n",
       " 634,\n",
       " 1516,\n",
       " 1013,\n",
       " 67,\n",
       " 78,\n",
       " 593,\n",
       " 1512,\n",
       " 700,\n",
       " 92,\n",
       " 600,\n",
       " 1288,\n",
       " 961,\n",
       " 1514,\n",
       " 1145,\n",
       " 951,\n",
       " 114,\n",
       " 1212,\n",
       " 656,\n",
       " 624,\n",
       " 1169,\n",
       " 766,\n",
       " 155,\n",
       " 672,\n",
       " 990,\n",
       " 1491,\n",
       " 168,\n",
       " 637,\n",
       " 282,\n",
       " 361,\n",
       " 27,\n",
       " 177,\n",
       " 53,\n",
       " 296,\n",
       " 1095,\n",
       " 426,\n",
       " 878,\n",
       " 55,\n",
       " 568,\n",
       " 737,\n",
       " 413,\n",
       " 913,\n",
       " 1268,\n",
       " 1457,\n",
       " 362,\n",
       " 203,\n",
       " 1027,\n",
       " 1060,\n",
       " 89,\n",
       " 87,\n",
       " 1290,\n",
       " 736,\n",
       " 1201,\n",
       " 1195,\n",
       " 119,\n",
       " 343,\n",
       " 1094,\n",
       " 824,\n",
       " 182,\n",
       " 805,\n",
       " 25,\n",
       " 433,\n",
       " 516,\n",
       " 1208,\n",
       " 929,\n",
       " 559,\n",
       " 1026,\n",
       " 793,\n",
       " 348,\n",
       " 1250,\n",
       " 1204,\n",
       " 1089,\n",
       " 974,\n",
       " 567,\n",
       " 1341,\n",
       " 738,\n",
       " 1304,\n",
       " 580,\n",
       " 17,\n",
       " 1059,\n",
       " 1378,\n",
       " 711,\n",
       " 1037,\n",
       " 310,\n",
       " 976,\n",
       " 1220,\n",
       " 321,\n",
       " 58,\n",
       " 394,\n",
       " 64,\n",
       " 1431,\n",
       " 591,\n",
       " 74,\n",
       " 1214,\n",
       " 303,\n",
       " 822,\n",
       " 702,\n",
       " 710,\n",
       " 1362,\n",
       " 292,\n",
       " 773,\n",
       " 908,\n",
       " 1342,\n",
       " 455,\n",
       " 1083,\n",
       " 7,\n",
       " 1146,\n",
       " 1261,\n",
       " 544,\n",
       " 1354,\n",
       " 721,\n",
       " 1142,\n",
       " 560,\n",
       " 1383,\n",
       " 1476,\n",
       " 1104,\n",
       " 684,\n",
       " 189,\n",
       " 707,\n",
       " 617,\n",
       " 926,\n",
       " 485,\n",
       " 892,\n",
       " 893,\n",
       " 673,\n",
       " 1380,\n",
       " 1482,\n",
       " 1198,\n",
       " 799,\n",
       " 845,\n",
       " 860,\n",
       " 1373,\n",
       " 70,\n",
       " 533,\n",
       " 859,\n",
       " 772,\n",
       " 920,\n",
       " 1311,\n",
       " 1002,\n",
       " 499,\n",
       " 865,\n",
       " 3,\n",
       " 542,\n",
       " 958,\n",
       " 914,\n",
       " 891,\n",
       " 127,\n",
       " 1483,\n",
       " 726,\n",
       " 1058,\n",
       " 1371,\n",
       " 101,\n",
       " 486,\n",
       " 776,\n",
       " 806,\n",
       " 491,\n",
       " 28,\n",
       " 549,\n",
       " 494,\n",
       " 48,\n",
       " 21,\n",
       " 442,\n",
       " 652,\n",
       " 253,\n",
       " 1449,\n",
       " 1221,\n",
       " 1384,\n",
       " 329,\n",
       " 584,\n",
       " 712,\n",
       " 1448,\n",
       " 1473,\n",
       " 601,\n",
       " 952,\n",
       " 883,\n",
       " 1008,\n",
       " 830,\n",
       " 1108,\n",
       " 864,\n",
       " 387,\n",
       " 1444,\n",
       " 1224,\n",
       " 298,\n",
       " 1338,\n",
       " 369,\n",
       " 610,\n",
       " 1523,\n",
       " 1421,\n",
       " 38,\n",
       " 490,\n",
       " 1014,\n",
       " 857,\n",
       " 1528,\n",
       " 322,\n",
       " 758,\n",
       " 1329,\n",
       " 419,\n",
       " 628,\n",
       " 1419,\n",
       " 1141,\n",
       " 297,\n",
       " 1465,\n",
       " 181,\n",
       " 1481,\n",
       " 65,\n",
       " 1425,\n",
       " 1258,\n",
       " 1282,\n",
       " 1274,\n",
       " 1031,\n",
       " 1122,\n",
       " 1194,\n",
       " 240,\n",
       " 1475,\n",
       " 818,\n",
       " 753,\n",
       " 667,\n",
       " 760,\n",
       " 339,\n",
       " 402,\n",
       " 1197,\n",
       " 259,\n",
       " 1137,\n",
       " 1296,\n",
       " 1091,\n",
       " 727,\n",
       " 1402,\n",
       " 689,\n",
       " 496,\n",
       " 1303,\n",
       " 524,\n",
       " 903,\n",
       " 1225,\n",
       " 732,\n",
       " 927,\n",
       " 730,\n",
       " 138,\n",
       " 1240,\n",
       " 531,\n",
       " 422,\n",
       " 1247,\n",
       " 648,\n",
       " 150,\n",
       " 167,\n",
       " 802,\n",
       " 582,\n",
       " 1447,\n",
       " 547,\n",
       " 124,\n",
       " 1040,\n",
       " 543,\n",
       " 1125,\n",
       " 832,\n",
       " 1209,\n",
       " 564,\n",
       " 1385,\n",
       " 1205,\n",
       " 1210,\n",
       " 272,\n",
       " 230,\n",
       " 1340,\n",
       " 123,\n",
       " 850,\n",
       " 1068,\n",
       " 493,\n",
       " 279,\n",
       " 1102,\n",
       " 1160,\n",
       " 1251,\n",
       " 170,\n",
       " 723,\n",
       " 605,\n",
       " 1326,\n",
       " 670,\n",
       " 360,\n",
       " 1147,\n",
       " 934,\n",
       " 383,\n",
       " 751,\n",
       " 965,\n",
       " 1252,\n",
       " 514,\n",
       " 495,\n",
       " 1332,\n",
       " 1055,\n",
       " 569,\n",
       " 175,\n",
       " 1388,\n",
       " 193,\n",
       " 1080,\n",
       " 440,\n",
       " 846,\n",
       " 116,\n",
       " 1134,\n",
       " 529,\n",
       " 288,\n",
       " 1123,\n",
       " 488,\n",
       " 695,\n",
       " 11,\n",
       " 1524,\n",
       " 752,\n",
       " 1043,\n",
       " 31,\n",
       " 708,\n",
       " 415,\n",
       " 1188,\n",
       " 330,\n",
       " 307,\n",
       " 278,\n",
       " 106,\n",
       " 1406,\n",
       " 1281,\n",
       " 735,\n",
       " 1213,\n",
       " 894,\n",
       " 1470,\n",
       " 963,\n",
       " 166,\n",
       " 1451,\n",
       " 691,\n",
       " 1525,\n",
       " 194,\n",
       " 468,\n",
       " 318,\n",
       " 1310,\n",
       " 1105,\n",
       " 658,\n",
       " 1184,\n",
       " 1430,\n",
       " 1200,\n",
       " 317,\n",
       " 340,\n",
       " 384,\n",
       " 849,\n",
       " 627,\n",
       " 1353,\n",
       " 835,\n",
       " 258,\n",
       " 619,\n",
       " 882,\n",
       " 553,\n",
       " 46,\n",
       " 783,\n",
       " 316,\n",
       " 1372,\n",
       " 609,\n",
       " 450,\n",
       " 520,\n",
       " 682,\n",
       " 595,\n",
       " 178,\n",
       " 631,\n",
       " 1279,\n",
       " 1350,\n",
       " 1167,\n",
       " 719,\n",
       " 198,\n",
       " 44,\n",
       " 24,\n",
       " 1327,\n",
       " 507,\n",
       " 906,\n",
       " 6,\n",
       " 1343,\n",
       " 1489,\n",
       " 1506,\n",
       " 1324,\n",
       " 1440,\n",
       " 579,\n",
       " 218,\n",
       " 260,\n",
       " 1046,\n",
       " 843,\n",
       " 970,\n",
       " 703,\n",
       " 1381,\n",
       " 1121,\n",
       " 489,\n",
       " 102,\n",
       " 674,\n",
       " 787,\n",
       " 731,\n",
       " 1376,\n",
       " 761,\n",
       " 480,\n",
       " 663,\n",
       " 788,\n",
       " 125,\n",
       " 1238,\n",
       " 107,\n",
       " 311,\n",
       " 566,\n",
       " 808,\n",
       " 1241,\n",
       " 57,\n",
       " 1234,\n",
       " 923,\n",
       " 1484,\n",
       " 1520,\n",
       " 967,\n",
       " 705,\n",
       " 1495,\n",
       " 774,\n",
       " 972,\n",
       " 763,\n",
       " 964,\n",
       " 427,\n",
       " 1454,\n",
       " 1237,\n",
       " 500,\n",
       " 1151,\n",
       " 841,\n",
       " 231,\n",
       " 1078,\n",
       " 357,\n",
       " 786,\n",
       " 1509,\n",
       " 1168,\n",
       " 1295,\n",
       " 916,\n",
       " 375,\n",
       " 797,\n",
       " 1005,\n",
       " 174,\n",
       " 1273,\n",
       " 836,\n",
       " 268,\n",
       " 144,\n",
       " 274,\n",
       " 556,\n",
       " 589,\n",
       " 921,\n",
       " 1348,\n",
       " 1183,\n",
       " 1301,\n",
       " 780,\n",
       " 1344,\n",
       " 59,\n",
       " 1496,\n",
       " 327,\n",
       " 552,\n",
       " 1191,\n",
       " 1186,\n",
       " 917,\n",
       " 1217,\n",
       " 1355,\n",
       " 380,\n",
       " 629,\n",
       " 1087,\n",
       " 255,\n",
       " 1398,\n",
       " 96,\n",
       " 1032,\n",
       " 261,\n",
       " 1312,\n",
       " 505,\n",
       " 508,\n",
       " 534,\n",
       " 273,\n",
       " 1478,\n",
       " 823,\n",
       " 367,\n",
       " 447,\n",
       " 1356,\n",
       " 561,\n",
       " 1229,\n",
       " 650,\n",
       " 1114,\n",
       " 1232,\n",
       " 140,\n",
       " 686,\n",
       " 471,\n",
       " 804,\n",
       " 30,\n",
       " 1379,\n",
       " 391,\n",
       " 234,\n",
       " 1438,\n",
       " 980,\n",
       " 594,\n",
       " 519,\n",
       " 1090,\n",
       " 1159,\n",
       " 585,\n",
       " 235,\n",
       " 137,\n",
       " 901,\n",
       " 349,\n",
       " 819,\n",
       " 281,\n",
       " 452,\n",
       " 1405,\n",
       " 803,\n",
       " 998,\n",
       " 1518,\n",
       " 696,\n",
       " 1521,\n",
       " 785,\n",
       " 565,\n",
       " 1487,\n",
       " 91,\n",
       " 988,\n",
       " 959,\n",
       " 346,\n",
       " 164,\n",
       " 1175,\n",
       " 104,\n",
       " 861,\n",
       " 263,\n",
       " 290,\n",
       " 982,\n",
       " 80,\n",
       " 120,\n",
       " 1063,\n",
       " 867,\n",
       " 749,\n",
       " 606,\n",
       " 401,\n",
       " 335,\n",
       " 633,\n",
       " 324,\n",
       " 4,\n",
       " 1015,\n",
       " 801,\n",
       " 232,\n",
       " 201,\n",
       " 404,\n",
       " 1144,\n",
       " 1235,\n",
       " 1174,\n",
       " 308,\n",
       " 779,\n",
       " 1172,\n",
       " 1298,\n",
       " 743,\n",
       " 1044,\n",
       " 331,\n",
       " 748,\n",
       " 216,\n",
       " 388,\n",
       " 79,\n",
       " 950,\n",
       " 635,\n",
       " 1020,\n",
       " 611,\n",
       " 1084,\n",
       " 243,\n",
       " 855,\n",
       " 1395,\n",
       " 492,\n",
       " 432,\n",
       " 56,\n",
       " 769,\n",
       " 782,\n",
       " 1180,\n",
       " 400,\n",
       " 1309,\n",
       " 40,\n",
       " 1173,\n",
       " 877,\n",
       " 1101,\n",
       " 679,\n",
       " 1357,\n",
       " 1130,\n",
       " 971,\n",
       " 503,\n",
       " 409,\n",
       " 69,\n",
       " 944,\n",
       " 848,\n",
       " 986,\n",
       " 199,\n",
       " 973,\n",
       " 187,\n",
       " 195,\n",
       " 621,\n",
       " 217,\n",
       " 1193,\n",
       " 390,\n",
       " 1262,\n",
       " 460,\n",
       " 477,\n",
       " 399,\n",
       " 1192,\n",
       " 1450,\n",
       " 642,\n",
       " 809,\n",
       " 816,\n",
       " 1305,\n",
       " 1156,\n",
       " 800,\n",
       " 37,\n",
       " 134,\n",
       " 163,\n",
       " 62,\n",
       " 208,\n",
       " 431,\n",
       " 73,\n",
       " 271,\n",
       " 541,\n",
       " 1219,\n",
       " 1010,\n",
       " 84,\n",
       " 250,\n",
       " 1124,\n",
       " 1392,\n",
       " 129,\n",
       " 744,\n",
       " 759,\n",
       " 983,\n",
       " 1076,\n",
       " 931,\n",
       " 671,\n",
       " 676,\n",
       " 429,\n",
       " 625,\n",
       " 1503,\n",
       " 616,\n",
       " 171,\n",
       " 77,\n",
       " 1082,\n",
       " 241,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result = pd.DataFrame({'name': preds_filenames, 'invasive': preds[:,0]})\n",
    "df_result = df_result.sort_values(\"name\")\n",
    "df_result.index = df_result[\"name\"]\n",
    "df_result = df_result.drop([\"name\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>invasive</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.630535e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.814070e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.577948e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8.262738e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.450361e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.125239e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.276554e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.787649e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.008932e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.396555e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.213693e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.063289e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4.208840e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2.686226e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4.589289e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1512</th>\n",
       "      <td>6.343188e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>5.931159e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1515</th>\n",
       "      <td>1.003395e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1516</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1517</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1518</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1519</th>\n",
       "      <td>4.541253e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1520</th>\n",
       "      <td>7.073062e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>9.635171e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>5.338651e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>9.999999e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1526</th>\n",
       "      <td>6.397620e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1527</th>\n",
       "      <td>1.115982e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1528</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1529</th>\n",
       "      <td>8.253364e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1530</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1531</th>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1531 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          invasive\n",
       "name              \n",
       "1     1.000000e+00\n",
       "2     3.630535e-04\n",
       "3     4.814070e-02\n",
       "4     3.577948e-02\n",
       "5     1.000000e+00\n",
       "6     8.262738e-05\n",
       "7     5.450361e-02\n",
       "8     1.000000e+00\n",
       "9     1.000000e+00\n",
       "10    3.125239e-06\n",
       "11    1.276554e-06\n",
       "12    5.787649e-04\n",
       "13    1.008932e-03\n",
       "14    1.000000e+00\n",
       "15    3.396555e-04\n",
       "16    1.213693e-02\n",
       "17    6.063289e-10\n",
       "18    4.208840e-03\n",
       "19    2.686226e-05\n",
       "20    4.589289e-01\n",
       "...            ...\n",
       "1512  6.343188e-05\n",
       "1513  5.931159e-07\n",
       "1514  1.000000e+00\n",
       "1515  1.003395e-07\n",
       "1516  1.000000e+00\n",
       "1517  1.000000e+00\n",
       "1518  1.000000e+00\n",
       "1519  4.541253e-03\n",
       "1520  7.073062e-03\n",
       "1521  9.635171e-04\n",
       "1522  5.338651e-03\n",
       "1523  1.000000e+00\n",
       "1524  9.999999e-01\n",
       "1525  1.000000e+00\n",
       "1526  6.397620e-03\n",
       "1527  1.115982e-12\n",
       "1528  1.000000e+00\n",
       "1529  8.253364e-07\n",
       "1530  1.000000e+00\n",
       "1531  1.000000e+00\n",
       "\n",
       "[1531 rows x 1 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_result.to_csv(\"submission_01.csv\", encoding=\"utf8\", index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='submission_01.csv' target='_blank'>submission_01.csv</a><br>"
      ],
      "text/plain": [
       "/home/ubuntu/extvol/kaggle-invasive-species-monitoring/submission_01.csv"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink('submission_01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Got 0.98680 on LB"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "153px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": true,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
